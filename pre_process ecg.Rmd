---
title: "pre_process_ecg"
author: "Helio"
date: "2024-03-09"
output: html_document
---




ECG signals



Set-up: where I load libraries and create objects for later use (such as color schemes etc).
```{r setup, include=FALSE}
# Load necessary libraries
require(tidyverse)
require(data.table)
library(janitor)
library(purrr)
require(readr)


```


Initiate exploration of strategies to correct file naming inconsistencies due to RA errors. This commit focuses on developing a methodical approach to detect, report, and correct instances where participant identifiers have been reused or incorrectly labeled across our dataset. This is crucial for ensuring data integrity and reliability, especially for identifiers 118, 119, 222, and 223, which have been identified as problematic. The aim is to automate as much of this correction process as possible, reducing the need for manual intervention and decreasing the likelihood of similar issues arising in the future. Details on the proposed solutions and their implementation will be shared in subsequent updates.


```{r}


setwd("~/Library/CloudStorage/OneDrive-UniversityofBristol/Research Projects/EmotionPhysio2024/2023-24 Project/Data backup/Consensys-physio/Calibrated")

# List of .csv files, assuming you've already created 'tmp_files' with list.files()
# tmp_files <- list.files(pattern = "\\._PCcsv$", recursive = FALSE, full.names = TRUE)
tmp_files_pc <- list.files(pattern = "ECG.*PC\\.csv$", recursive = FALSE, full.names = TRUE)

tmp_files_sd <- list.files(pattern = "ECG.*SD\\.csv$", recursive = FALSE, full.names = TRUE)


# Extract identifiers

# Regular expression to capture the pattern before "_" and after "./"
# pattern <- "^\\./(.+)_ECG"

# sub("^\\./(.+)_ECG.*$", "\\1", tmp_files_pc)


identifiers_tmp_files_pc <- sub("^\\./(.+)_ECG.*$", "\\1", tmp_files_pc)
identifiers_tmp_files_sd <- sub("^\\./(.+)_ECG.*$", "\\1", tmp_files_sd)

# Compare and find common identifiers
tmp_common_identifiers <- intersect(identifiers_tmp_files_pc, identifiers_tmp_files_sd)

# Display the common identifiers
tmp_common_identifiers
# length(tmp_common_identifiers) # 51

# Identifiers unique to PC files
tmp_unique_identifiers_pc <- setdiff(identifiers_tmp_files_pc, identifiers_tmp_files_sd)

# ADDED DB 103
# Identifiers unique to SD files
tmp_unique_identifiers_sd <- setdiff(identifiers_tmp_files_sd, identifiers_tmp_files_pc)
# [1] "104_Session1" "105_Session1" "107_Session1" "108_Session1" "110_Session1"
#  [6] "111_Session1" "112_Session1" "113_Session1" "114_Session1" "119_Session2"
# [11] "120_Session1" "126_Session1" "127_Session1" "201_Session1" "202_Session1"
# [16] "204_Session1" "205_Session1" "208_Session1" "209_Session1" "213_Session1"
# [21] "214_Session2" "215_Session1" "220_Session1" "223_Session2" "224_Session1"
# [26] "230_Session1"
#### 119 was mistaklenly set as 118
# 220 noted missing in logbook


# now we want to create a list that contains tmp_files_pc plus the tmp_unique_identifiers_sd

# Assuming tmp_unique_identifiers_sd contains unique identifiers like c("101", "102", "106")
# Create a regular expression pattern that matches any of these identifiers
pattern_unique_sd <- paste(tmp_unique_identifiers_sd, collapse = "|")

# Use grep to select files from tmp_files_sd that match the unique identifiers
tmp_selected_files_sd <- tmp_files_sd[grep(pattern_unique_sd, tmp_files_sd)]

# Display the selected files
tmp_selected_files_sd

# Combine selected_files_sd with tmp_files_pc
tmp_combined_list <- c(tmp_files_pc,tmp_selected_files_sd)

# Display the combined vector

tmp_combined_list
# remember to update 000_Session1_ECG_Calibrated_PC to 2176?

# so we are picking up all files
 grep("223", tmp_combined_list, value=TRUE)
 grep("223", tmp_files_sd, value=TRUE)

```


select col names
```{r}
###################################################

tmp_combined_list
# do we actually want to store all of thes efiles here, or just load each adjut then save it back due to memory issues
setDT(dta_psypy1)
# dta_psypy1$orig_unixtime_start_psypy<- dta_psypy1$unixtime_start



# Predefined column names
column_names <- c( "ecg_timestamp_sync_unix_cal_ms", "ecg_battery_cal_m_v",
                  "ecg_ecg_emg_status1_cal_no_units", "ecg_ecg_emg_status2_cal_no_units",
                  "ecg_ecg_ibi_ll_ra_cal_ms", "ecg_ecg_ibi_vx_rl_cal_ms",
                  "ecg_ecg_la_ra_24bit_cal_m_v", "ecg_ecg_ll_la_24bit_cal_m_v",
                  "ecg_ecg_ll_ra_24bit_cal_m_v", "ecg_ecg_vx_rl_24bit_cal_m_v",
                  "ecg_ec_gto_hr_ll_ra_cal_bpm", "ecg_ec_gto_hr_vx_rl_cal_bpm",
                  "ecg_pressure_bmp280_cal_k_pa", "ecg_temperature_bmp280_cal_degrees_celsius")



# Assuming participant_ids and other necessary data are already defined

participant_ids <- unique(dta_psypy1$participant)
participant_ids
tmp_combined_list




```

skip this



load merge triggers and export - so this will still be rawish - i.e no procesing

multisesion as one

223 - dos separately PC and SD have different sessions that are actually the sa
```{r}
setwd("~/Library/CloudStorage/OneDrive-UniversityofBristol/Research Projects/EmotionPhysio2024/2023-24 Project/Data backup/Consensys-physio/Calibrated/ecg_wtriggers")

# Ensure that file_df is correctly created and available before this script runs.

 # Helper function to extract participant ID and session from filename
extract_info <- function(filename) {
  parts <- str_match(filename, ".*/(\\d+)_Session(\\d+)_ECG_Calibrated_.*\\.csv$")
  return(list(participant_id = parts[, 2], session = parts[, 3]))
}

# Create a dataframe to map participant IDs and sessions to file paths
file_info <- sapply(tmp_combined_list, function(x) extract_info(x), simplify = FALSE)
file_df <- do.call(rbind, lapply(file_info, function(x) data.frame(participant_id = x$participant_id, session = x$session, stringsAsFactors = FALSE)))
file_df$filepath <- tmp_combined_list

# participant_id = 134
# rm(participant_id)
# participant_ids
# 119


library(data.table) # Ensure data.table is loaded
library(dplyr)      # Ensure dplyr is loaded

library(readr)
# X210_Session1_ECG_Calibrated_SD <- read_csv("210_Session1_ECG_Calibrated_SD.csv")
participant_id = 210
# participant_id = 223
View(X210_Session1_ECG_Calibrated_SD)

for (participant_id in unique(file_df$participant_id)) {
  # Find all files for this participant
  participant_files <- file_df[file_df$participant_id == participant_id, ]
  
  # Initialize an empty list to hold session data
  all_sessions_data <- list()
  
  for (i in 1:nrow(participant_files)) {
    
    message("\nProcessing Participant ID: ", participant_id)
    # Load and process each file
    # 210_Session1_ECG_Calibrated_SD.csv
    filepath <- participant_files$filepath[i]
    # filepath<- "./210_Session1_ECG_Calibrated_SD.csv"
    # session = 1
     # "./223_Session2_ECG_Calibrated_SD.csv"
    session <- participant_files$session[i]

    # Read the CSV file, skip the first 3 rows
    tmp_ecg <- fread(filepath, skip = 3, header = FALSE)
    
    # Remove extra columns if necessary
    extra_cols <- ncol(tmp_ecg) - length(column_names)
    if (extra_cols > 0) {
      tmp_ecg <- tmp_ecg[, -((ncol(tmp_ecg)-extra_cols+1):ncol(tmp_ecg)), with = FALSE]
    }
    
    # Assign predefined column names
    setnames(tmp_ecg, old = names(tmp_ecg), new = column_names)
    
    # Add a new column with the filename
    filename <- basename(filepath)
    tmp_ecg[, filename := filename]
    
    tmp_ecg[, session := session]
    
    # Correct original timestamp column name
    tmp_ecg[, orig_timestamp_ecg := ecg_timestamp_sync_unix_cal_ms]
    
    # Merge timestamps and other operations from dta_psypy1
    tmp_psypy <- dta_psypy1[participant == participant_id, .(participant, social_nonsocial, stim_iaps, trial_no_all, unixtime_start, orig_unixtime_start_psypy)]
    tmp_psypy[, next_unixtime_start := shift(unixtime_start, type = "lead", fill = Inf)]
    tmp_psypy[, unixtime_end := next_unixtime_start - 1]
    
    # Initialize missing columns in tmp_ecg
    tmp_ecg[, `:=` (social_nonsocial = as.character(NA), 
                    stim_iaps = as.character(NA), 
                    trial_no_all = as.integer(NA), 
                    psypy_unixtime_start = as.numeric(NA),
                    orig_unixtime_start_psypy = as.numeric(NA))]
    
    # Perform the non-equi join and update
    tmp_ecg[tmp_psypy, on = .(ecg_timestamp_sync_unix_cal_ms >= unixtime_start, 
                              ecg_timestamp_sync_unix_cal_ms <= unixtime_end), 
            `:=` (social_nonsocial = i.social_nonsocial, 
                  stim_iaps = i.stim_iaps, 
                  trial_no_all = i.trial_no_all, 
                  psypy_unixtime_start = i.unixtime_start,
                  orig_unixtime_start_psypy = i.orig_unixtime_start_psypy), 
            by = .EACHI]
    
    # Append the processed session data to the list
    all_sessions_data[[length(all_sessions_data) + 1]] <- tmp_ecg
  }
  
  # Combine data from all sessions
  combined_data <- do.call(rbind, all_sessions_data)
  
  # Convert combined data to tibble for dplyr operations
  combined_data <- as_tibble(combined_data)
  
  # Apply dplyr operations
  combined_data <- combined_data %>%
    arrange(ecg_timestamp_sync_unix_cal_ms) %>%
    mutate(start_true = !duplicated(trial_no_all) & !is.na(trial_no_all),
           trigger = case_when(
             trial_no_all == 1 & start_true == TRUE ~ 1,
             start_true == FALSE ~ 0,
             TRUE ~ as.numeric(trial_no_all)),
           ecg_timerezero_sync_unix_cal_ms = ecg_timestamp_sync_unix_cal_ms - first(ecg_timestamp_sync_unix_cal_ms))
  
  # Save the combined and processed data to a CSV file
  fwrite(as.data.table(combined_data), paste0(participant_id, "_allsessions", "_dta_ecg_trig.csv"), row.names = FALSE)
  
  # Print completion message for current participant
  message("Completed processing for Participant ID: ", participant_id)
}


```

note 103 is mising ecg data but this is present in database so we need to load up manualy from sql
quick checks

```{r}
# Load necessary libraries
# install.packages("RSQLite")
# install.packages("DBI")
library(RSQLite)
library(DBI)

setwd("/Users/pw22812/Library/CloudStorage/OneDrive-UniversityofBristol/Research Projects/EmotionPhysio2024/2023-24 Project/Data backup/Consensys-physio/103/Raw data/1706540442")

# Specify the path to your SQLite database file
db_path <- "~Library/CloudStorage/OneDrive-UniversityofBristol/Research Projects/EmotionPhysio2024/2023-24 Project/Data backup/Consensys-physio/103/Raw data/1706540442/1706540442.db" # Replace with your actual file path

# Establish a connection to the SQLite database
conn <- dbConnect(RSQLite::SQLite(), dbname = db_path)

# Specify the table you want to download
table_name <- "Calibrated_BT_fc0fe7b56da3"

# Read the table into a data frame
data <- dbReadTable(conn, table_name)

# Specify the path where you want to save the CSV file
csv_path <- "path/to/where/you/want/Calibrated_BT_fc0fe7b56da3.csv" # Replace with your actual save path

# Write the data frame to a CSV file
write.csv(data, csv_path, row.names = FALSE)

# Close the connection
dbDisconnect(conn)
```



```{r}
colnames(tmp_ecg)
 tmp_ecg %>%
    arrange(ecg_timestamp_sync_unix_cal_ms) %>%
  group_by(trial_no_all) %>%
  mutate(start_true = !duplicated(trial_no_all) & !is.na(trial_no_all)) %>%
  
  mutate(time = ifelse(start_true, ecg_timestamp_sync_unix_cal_ms, NA)) %>%
  # Use `fill` to propagate the first timestamp down the group
  fill(time, .direction = "down")%>%
  ungroup()%>%
  arrange(ecg_timestamp_sync_unix_cal_ms)%>%
  # subset(trial_no_all>15 & trial_no_all<20)%>%
  mutate(time_diff_psypy_gsr = orig_unixtime_start_psypy-orig_unixtime_start_psypy)%>%
  ggplot( aes(x = ecg_timestamp_sync_unix_cal_ms, 
                         y = ecg_ec_gto_hr_ll_ra_cal_bpm)) +
  geom_line() +
  # Add red vertical lines at 'time' for the start of each trial
  geom_vline(aes(xintercept = time), color = "red") 
 
 
  tmp_ecg %>%
    arrange(ecg_timestamp_sync_unix_cal_ms) %>%
  group_by(trial_no_all) %>%
  # mutate(start_true = !duplicated(trial_no_all) & !is.na(trial_no_all)) %>%
  
  mutate(time = ifelse(start_true, ecg_timestamp_sync_unix_cal_ms, NA)) %>%
  # Use `fill` to propagate the first timestamp down the group
  fill(time, .direction = "down")%>%
  ungroup()%>%
  arrange(ecg_timestamp_sync_unix_cal_ms)%>%
  # subset(trial_no_all>15 & trial_no_all<20)%>%
  mutate(time_diff_psypy_gsr = orig_unixtime_start_psypy-orig_unixtime_start_psypy)%>%
  ggplot( aes(x = ecg_timestamp_sync_unix_cal_ms, 
                         y = ecg_ec_gto_hr_ll_ra_cal_bpm)) +
  geom_line() +
  # Add red vertical lines at 'time' for the start of each trial
  geom_vline(aes(xintercept = time), color = "red") 
 
 
 
 
 # IBI
 unique( tmp_ecg$ecg_ecg_ibi_ll_ra_cal_ms)
 
 
 tmp_ecg %>%
    arrange(ecg_timestamp_sync_unix_cal_ms) %>%
  group_by(trial_no_all) %>%
  mutate(start_true = !duplicated(trial_no_all) & !is.na(trial_no_all)) %>%


  mutate(time = ifelse(start_true, ecg_timestamp_sync_unix_cal_ms, NA)) %>%

  # Use `fill` to propagate the first timestamp down the group
  fill(time, .direction = "down")%>%
  ungroup()%>%
  arrange(ecg_timestamp_sync_unix_cal_ms)%>%
         subset(ecg_ecg_ibi_ll_ra_cal_ms> 0 )%>%
  subset(trial_no_all>15 & trial_no_all<20)%>%
  mutate(time_diff_psypy_gsr = orig_unixtime_start_psypy-orig_unixtime_start_psypy)%>%
  ggplot( aes(x = ecg_timestamp_sync_unix_cal_ms, 
                         y = ecg_ecg_ibi_ll_ra_cal_ms)) +
  geom_point(size = .00001) +
   geom_line(size = .1)+
  # Add red vertical lines at 'time' for the start of each trial
  geom_vline(aes(xintercept = time), color = "red") 

 options(scipen = 999)
 
 tmp_gsr$filename
 tmp_ecg$filename
 
# tmp_ecg$orig_timestamp_ecg[tmp_ecg$start_true == TRUE]-
# tmp_gsr$orig_timestamp_gsr[tmp_gsr$start_true == TRUE]
 
 # this difference should be pretty small and it is close to 1 ms, which is great
```

[1] -1.38330078  1.89526367 -4.51904297 -2.84741211  2.70336914  3.34204102 -3.37255859
 [8] -0.88989258 -2.88159180  0.59008789 -0.29345703  0.04248047 -2.20581055 -5.65771484
[15] -1.18432617 -4.25805664  0.17578125 -4.96362305 -0.14355469 -6.34448242  1.48095703
[22] -4.22753906 -1.11303711 -4.90869141 -4.12866211 -0.66748047 -4.19775391  0.46020508
[29] -5.09057617 -3.11108398  0.88183594 -1.17407227 -3.05859375 -5.82446289 -0.14453125
[36] -6.11572266 -4.53393555  0.69726562  1.80908203  0.38989258 -0.66479492 -0.09057617
[43] -4.64746094  0.43823242 -6.83593750 -1.65405273 -3.28808594  0.71997070 -0.89892578
[50] -1.68627930 -1.86425781 -4.26074219 -0.76806641  0.58715820  1.12573242 -4.09643555
[57] -1.47729492  3.52734375  2.04956055 -5.97534180  2.72998047  0.77148438  1.63110352
[64] -0.84375000 -1.84399414
to do in ECG
smooth check artifacts and interpolate

to do later
- compare peak detecion 

```{r}



# Step 1: Read the first two rows to get column names and units


# read_delim("110_Session1_GSRPulse_Calibrated_PC.csv", 
#     delim = "\t", escape_double = FALSE, 


dta_ecg_header_info <-  read_delim("116_Session1_ECG_Calibrated_PC.csv", 
                                    # nrows = 2, 
                                    skip = 1,
                                    escape_double = FALSE, 
                                    delim = "\t")

dta_ecg <-  read_delim("116_Session1_ECG_Calibrated_PC.csv", 
                                    # nrows = 2, 
                                    skip = 2,
                                    escape_double = FALSE, 
                                    delim = "\t")

colnames(dta_ecg)


names(dta_ecg)<- paste0(colnames(dta_ecg_header_info),"_", paste0(dta_ecg_header_info[1,]))


dta_ecg$...15_NA<-NULL


# make clean names
dta_ecg<- dta_ecg%>%
  janitor::clean_names()


colnames(dta_ecg)

# ECG heart rate
dta_ecg%>%
  mutate(time_rezero = ecg_timestamp_sync_unix_cal_ms-ecg_timestamp_sync_unix_cal_ms[1])%>%
  ggplot(aes(time_rezero,
             ecg_ec_gto_hr_ll_ra_cal_bpm))+
  geom_line()
  # geom_point()


# just ECG
dta_physio$gsr_pulse_timestamp_sync_unix_cal_ms-lag(dta_physio$gsr_pulse_timestamp_sync_unix_cal_ms)
dta_ecg$ecg_timestamp_sync_unix_cal_ms-lag(dta_ecg$ecg_timestamp_sync_unix_cal_ms)


# Calculate the sample rate given the sampling interval in seconds
# sampling_interval_seconds = 0.003998047
# sample_rate = 1 / sampling_interval_seconds
# 
# sample_rate

dta_ecg$ecg_ecg_emg_status1_cal_no_units
dta_ecg$ecg_ecg_emg_status2_cal_no_units

# ecg_ecg_ll_ra_24bit_cal_m_v = ECG signa;
# ecg_ec_gto_hr_ll_ra_cal_bpm = heart rate
# ecg_ecg_ibi_ll_ra_cal_ms = IBI



dta_ecg%>%
  mutate(time_rezero = ecg_timestamp_sync_unix_cal_ms-ecg_timestamp_sync_unix_cal_ms[1])%>%
  ggplot(aes(time_rezero,
             ecg_ecg_ll_ra_24bit_cal_m_v))+
  geom_line()


dta_ecg%>%
  mutate(time_rezero = ecg_timestamp_sync_unix_cal_ms-ecg_timestamp_sync_unix_cal_ms[1])%>%
  ggplot(aes(time_rezero,
             ecg_ecg_ll_ra_24bit_cal_m_v))+
  geom_line()



# IBI
dta_ecg%>%
  subset(ecg_ecg_ibi_ll_ra_cal_ms!=-1)%>%
  mutate(time_rezero = ecg_timestamp_sync_unix_cal_ms-ecg_timestamp_sync_unix_cal_ms[1])%>%
  ggplot(aes(time_rezero,
             ecg_ecg_ibi_ll_ra_cal_ms))+
  geom_line()


# expected cavare plot of R to R interval
dta_ecg%>%
  subset(ecg_ecg_ibi_ll_ra_cal_ms!=-1)%>%
  mutate(ecg_ecg_ibi_ll_ra_cal_ms_lag = lag(ecg_ecg_ibi_ll_ra_cal_ms))%>%
  ggplot(aes(ecg_ecg_ibi_ll_ra_cal_ms,
             ecg_ecg_ibi_ll_ra_cal_ms_lag))+
  geom_point()



dta_ecg%>%
  mutate(time_rezero = ecg_timestamp_sync_unix_cal_ms-ecg_timestamp_sync_unix_cal_ms[1])%>%
  ggplot(aes(time_rezero,
             ecg_temperature_bmp280_cal_degrees_celsius))+
  geom_line()


# EGG ecg_ecg_vx_rl_24bit_cal_m_v

dta_ecg%>%
  mutate(time_rezero = ecg_timestamp_sync_unix_cal_ms-ecg_timestamp_sync_unix_cal_ms[1])%>%
  ggplot(aes(time_rezero,
             ecg_ecg_vx_rl_24bit_cal_m_v))+
  geom_line()


```